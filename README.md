# ETRI_2023_AI_KCC
제2회 2023 ETRI 휴먼이해 인공지능 논문경진대회 

# Abstract
>인간은 언어적, 반언어적 요소를 통합적으로 파악하며, 감정을 인식합니다. 본 연구에서는 발화자의 텍스트와음성 및 생체 신호 데이터를 종합적으로 활용하여 중립, 기쁨, 슬픔, 놀람, 공포, 분노, 혐오 총 7가지 감정을 분류하는 멀티 모달리티 모델을 제안하였습니다. 그 결과, 단일 모달리티 모델보다 더 우수한 성능을 얻을 수 있었습니다. 따라서 감정 인식에 있어서 여러 모달리티를 종합적으로 활용하는 것이 효과적인 것을 알 수 있었습니다.
  
# 코드 내용
>Feature Extraction : 텍스트와 음성 데이터의 특징 벡터를 추출하는 파일입니다. 
>KFold_fusion_model : 텍스트, 음성, 생체 신호 데이터를 활용하여 Early fusion, Late fusion 방식으로 멀티모달 모델을 생성하는 파일입니다.<br>
> Preprocessing : 생체 신호 데이터를 전처리하고, 음성 데이터에 wav파일의 path를 추가하는 파일입니다.<br>
>(**데이터에 대한 정보는 해당 대회 주최측에서 비공개를 요청함**)
